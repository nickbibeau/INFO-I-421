---
title: "Decision Tree"
author: "Nicholas Bibeau"
date: "4/15/2019"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("rpart")
library("rpart.plot")
library("party")
library("tidyverse")
library("foreach")

# User-defined function to 
# 1. calculate Shannon entropy for a given vector 
# 2. visualize the distribution in a histogram

entropy.gini <- function(input, type=1, discrete=1){
  # a function to calculate Shannon entropy for a given vector
  # type: 1- categories in integers, continuous values
  # type: 2- class counts
  # when type=1, discrete: 1-discrete labels, 0-continuous labels
  
  if (type==1){
    if (discrete == 0){
      breaks <- c(floor(min(input)):ceiling(max(input)))
    } else {
      breaks <- c(min(input):(max(input)+1))
    }
    freq <- hist(input,include.lowest=TRUE,right=FALSE, breaks=breaks,col='lightblue')
    counts <- freq$counts
    total <- sum(counts)
    
  }
  else{
    breaks <- length(input)
    total <- sum(input)
    counts <- input
    hist(input)
  }
  
  entropy <- 0
  for(x in counts){
    if(x!=0)
      temp <- x/total*log2(x/total)
    else
      temp <- 0

    entropy <- entropy - temp
  }
  
  gini <- 1-sum((counts/total)**2)
  
  mylist <- list("breaks"=breaks,"entropy"=entropy,"gini"=gini)
  return(mylist)
}
```

# 1.2.2: Lenses Dataset

## Import Dataset
```{r}
lenses <- as_tibble(read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/lenses/lenses.data", header = FALSE, col.names=c("patient", "age", "prescription", "astigmatic", "tear_rate", "lens")))
# Drop unneccessary column "patient"
lenses <- lenses[,2:6]
```


## Calculating Entropy of Set

### 1: Group by lens type and count classes
```{r}
counts <- (lenses %>% 
  select(lens) %>%
  group_by(lens) %>%
  summarise(count=n())
  )$count
```

### 2: Computing Entropy of Whole Dataset
```{r}
entropy_set <- entropy.gini(counts, type=2)$entropy
# The entropy for the entire set is: 
entropy_set
```

## 3: Calculating Gain Based on Age

### 3.1: Looking at distribution in terms of three subsets by age
```{r}
info.before <- entropy_set
subsets.age <- table(lenses$age,lenses$lens)
subsets.age

subsets.age["1",]
subsets.age["2",]
subsets.age["3",]


```

### 3.2: Computing Entropy of Each Subset
```{r}
entropy.young <- entropy.gini(subsets.age["1",], type=2)$entropy
entropy.prepresbyopic <- entropy.gini(subsets.age["2",], type=2)$entropy
entropy.presbyopic <- entropy.gini(subsets.age["3",], type=2)$entropy
```

### 3.3: Computing Weighted Entropy
```{r}
total <- nrow(lenses)
w1 <- sum(subsets.age["1",])/total
w2 <- sum(subsets.age["2",])/total
w3 <- sum(subsets.age["3",])/total
info.age <- w1*entropy.young + w2*entropy.prepresbyopic + w3*entropy.presbyopic
```


### 3.4 Computing Information Gain of Age
```{r}
gain.age <- info.before - info.age
```


## 4: Calculating Gain Based on Spectacle Prescription

### 4.1: Looking at distribution in terms of three subsets by prescription
```{r}
subsets.script <- table(lenses$prescription,lenses$lens)
subsets.script

subsets.script["1",]
subsets.script["2",]
```

### 4.2: Computing Entropy of Each Subset
```{r}
entropy.myope <- entropy.gini(subsets.script["1",], type=2)$entropy
entropy.hypermetrope <- entropy.gini(subsets.script["2",], type=2)$entropy
```

### 4.3: Computing Weighted Entropy
```{r}
w_script1 <- sum(subsets.script["1",])/total
w_script2 <- sum(subsets.script["2",])/total
info.script <- w_script1*entropy.myope + w_script2*entropy.hypermetrope
```


### 4.4 Computing Information Gain of Prescription
```{r}
gain.script <- info.before - info.script
```


## 5: Calculating Gain Based on Astigmatism

### 5.1: Looking at distribution in terms of three subsets by astigmatism
```{r}
subsets.astigmatic <- table(lenses$astigmatic,lenses$lens)
subsets.astigmatic

subsets.astigmatic["1",]
subsets.astigmatic["2",]
```

### 5.2: Computing Entropy of Each Subset
```{r}
entropy.no <- entropy.gini(subsets.astigmatic["1",], type=2)$entropy
entropy.yes <- entropy.gini(subsets.astigmatic["2",], type=2)$entropy
```

### 5.3: Computing Weighted Entropy
```{r}
w_astigmatic1 <- sum(subsets.astigmatic["1",])/total
w_astigmatic2 <- sum(subsets.astigmatic["2",])/total
info.astigmatic <- w_astigmatic1*entropy.no + w_astigmatic2*entropy.yes
```


### 5.4 Computing Information Gain of Prescription
```{r}
gain.astigmatic <- info.before - info.astigmatic
```


## 6: Calculating Gain Based on Tear Production Rate

### 6.1: Looking at distribution in terms of three subsets by Tear Production Rate
```{r}
subsets.tear_rate <- table(lenses$tear_rate,lenses$lens)
subsets.tear_rate

subsets.tear_rate["1",]
subsets.tear_rate["2",]
```

### 6.2: Computing Entropy of Each Subset
```{r}
entropy.reduced <- entropy.gini(subsets.tear_rate["1",], type=2)$entropy
entropy.normal <- entropy.gini(subsets.tear_rate["2",], type=2)$entropy
```

### 6.3: Computing Weighted Entropy
```{r}
w_tear_rate1 <- sum(subsets.tear_rate["1",])/total
w_tear_rate2 <- sum(subsets.tear_rate["2",])/total
info.tear_rate <- w_tear_rate1*entropy.reduced + w_tear_rate2*entropy.normal
```


### 6.4 Computing Information Gain of Prescription
```{r}
gain.tear_rate <- info.before - info.tear_rate
```


## 7. Result
```{r}
# Tear Production rate yields the greatest information gain, and should be selected as the root node.
```


# 1.2.3 Scripting Previous Calcuations
```{r}
gains <- c(gain.age, gain.astigmatic, gain.script, gain.tear_rate)
max(gains)
# The largest gains are achieved through:
if (max(gains) == gains[1]) {print("Age")
  } else if (max(gains) ==gains[2]) {print("Astigmatism")
  } else if (max(gains) ==gains[3]) {print("Prescription")
  } else if (max(gains) ==gains[4]) {print("Tear Production Rate")
}

```

# 1.2.4: The gini index

## Finding gini for Age
```{r}
g_age1 <- entropy.gini(subsets.age["1",],type=2)$gini
g_age2 <- entropy.gini(subsets.age["2",],type=2)$gini
g_age3 <- entropy.gini(subsets.age["3",],type=2)$gini
#weighted sum
w_age1 <- sum(subsets.age["1",])/total
w_age2 <- sum(subsets.age["2",])/total
w_age3 <- sum(subsets.age["3",])/total
gini.age <- w_age1*g_age1 + w_age2*g_age2 + w_age3*g_age3 

```

## Finding gini for Spectacle Prescription
```{r}
g_script1 <- entropy.gini(subsets.script["1",],type=2)$gini
g_script2 <- entropy.gini(subsets.script["2",],type=2)$gini
#weighted sum
w_script1 <- sum(subsets.script["1",])/total
w_script2 <- sum(subsets.script["2",])/total
gini.script <- w_script1*g_script1 + w_script2*g_script2
```

## Finding gini for Astigmatism
```{r}
g_astigmatic1 <- entropy.gini(subsets.astigmatic["1",],type=2)$gini
g_astigmatic2 <- entropy.gini(subsets.astigmatic["2",],type=2)$gini
#weighted sum
w_astigmatic1 <- sum(subsets.astigmatic["1",])/total
w_astigmatic2 <- sum(subsets.astigmatic["2",])/total
gini.astigmatic <- w_astigmatic1*g_astigmatic1 + w_astigmatic2*g_astigmatic2
```

## Finding gini for Tear Production Rate
```{r}
g_tear_rate1 <- entropy.gini(subsets.tear_rate["1",],type=2)$gini
g_tear_rate2 <- entropy.gini(subsets.tear_rate["2",],type=2)$gini
#weighted sum
w_tear_rate1 <- sum(subsets.tear_rate["1",])/total
w_tear_rate2 <- sum(subsets.tear_rate["2",])/total
gini.tear_rate <- w_tear_rate1*g_tear_rate1 + w_tear_rate2*g_tear_rate2
```

## Scripting Conclusion
```{r}
ginis <- c(gini.age, gini.astigmatic, gini.script, gini.tear_rate)
min(ginis)
# The root should be:
if (min(ginis) == ginis[1]) {print("Age")
  } else if (min(ginis) ==ginis[2]) {print("Astigmatism")
  } else if (min(ginis) ==ginis[3]) {print("Prescription")
  } else if (min(ginis) ==ginis[4]) {print("Tear Production Rate")
}

```

# 1.2.5: Tree Models via rpart


```{r}
set.seed(20)
fit <- rpart(lens~age+prescription+astigmatic+tear_rate,
      method="class", data=lenses,
      control=rpart.control(minsplit = 1,cp=0),
      parms=list(split='information'))
summary(fit)
rpart.plot(fit,type=4,extra=2,roundint=FALSE)
```

